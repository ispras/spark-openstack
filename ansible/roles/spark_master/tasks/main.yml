---

- name: distribute hadoop masters file
  template: src=templates/masters.j2 dest=/usr/local/{{ hadoop_file }}/etc/hadoop/masters

- name: distribute hadoop slaves file
  template: src=templates/slaves.j2 dest=/usr/local/{{ hadoop_file }}/etc/hadoop/slaves

- name: format hdfs (unless it's already been done)
  command: /usr/local/{{ hadoop_file }}/bin/hadoop namenode -format creates=/usr/local/{{ hadoop_file }}/ansible-format-hdfs

- name: touch hfds formatted file (indicates if hdfs has been formatted)
  file: state=touch path=/usr/local/{{ hadoop_file }}/ansible-format-hdfs

- name: add hadoop and spark binaries to path for hadoop user
  lineinfile:
    dest=/home/{{ hadoop_user }}/.bashrc
    state=present insertafter=EOF
    line="export PATH=$PATH:/usr/local/{{ hadoop_file }}/bin/:/opt/{{ spark_file }}/bin/"
    create=true

- name: stop hdfs (if running)
  command: /usr/local/{{ hadoop_file }}/sbin/stop-dfs.sh

- name: start hdfs
  command: /usr/local/{{ hadoop_file }}/sbin/start-dfs.sh

- name: stop yarn (if running)
  command: /usr/local/{{ hadoop_file }}/sbin/stop-yarn.sh
  when: on_yarn

- name: start yarn
  command: /usr/local/{{ hadoop_file }}/sbin/start-yarn.sh
  when: on_yarn

- name: stop spark master (if running)
  command: /opt/{{ spark_file }}/sbin/stop-master.sh

- name: start spark master
  shell: SPARK_MASTER_IP="{{ cluster_name }}-master" /opt/{{ spark_file }}/sbin/start-master.sh

- name: stop the slaves (if running)
  shell: /opt/{{ spark_file }}/sbin/stop-slaves.sh

- name: start the slaves
  shell: /opt/{{ spark_file }}/sbin/start-slaves.sh
