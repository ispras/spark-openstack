---

- hosts: "{{ cluster_name }}_master:{{ cluster_name }}_slaves"
  become: yes
  become_user: root
  roles:
    - { role: ignite_prepare, when: deploy_ignite }
    - { role: cassandra, when: deploy_cassandra }
    - spark_common
    - { role: ignite_config, when: deploy_ignite }
    - mountnfs

- hosts: "{{ cluster_name }}_master"
  roles:
    - spark_master

- hosts: "{{ cluster_name }}_master"
  roles:
    - { role: jupyter, install_as_service: True, when: deploy_jupyter}
    - { role: jupyter, python_version: 3, when: deploy_jupyter}
    - { role: jupyterhub, python_version: 3, when: deploy_jupyterhub}



- hosts: "{{ cluster_name }}_master"
  become: yes
  become_user: root
  roles:
    - { role: elasticsearch, when: deploy_elastic, es_instance_name: "{{ cluster_name}}", es_heap_size: "1g",
    es_config: {
        cluster.name: "{{ cluster_name }}",
        discovery.zen.ping.unicast.hosts: "{{ active_master_ip }}:9300",
        http.port: 9200,
        transport.tcp.port: 9300,
        node.data: false,
        node.master: true,
        bootstrap.memory_lock: false,
        network.host: "0"
        }
    }
  vars:
    es_scripts: false
    es_templates: false
    es_version_lock: false
    es_plugins:
     - plugin: ingest-geoip



- hosts: "{{ cluster_name }}_slaves"
  become: yes
  become_user: root
  roles:
    - { role: elasticsearch, when: deploy_elastic, es_instance_name: "{{ cluster_name }}", es_data_dirs: "/opt/elasticsearch",
    es_config: {
        discovery.zen.ping.unicast.hosts: "{{ active_master_ip }}:9300",
        http.port: 9200,
        transport.tcp.port: 9300,
        node.data: true,
        node.master: false,
        bootstrap.memory_lock: false,
        cluster.name: "{{ cluster_name }}",
        network.host: "0"
        }
    }
  vars:
    es_scripts: false
    es_templates: false
    es_version_lock: false
    es_api_port: 9200
    es_plugins:
    - plugin: ingest-geoip



#- hosts: localhost
#  roles:
#    - { role: spark_common, just_import: True }
#  tasks:
#    - name: get Spark distro
#      get_url: url={{ spark_download_url }} dest={{ spark_arch }}
#    - name: get Hadoop distro
#      get_url: url={{ hadoop_download_url }} dest={{ hadoop_arch }}
#    - name: get Swift library (for Hadoop 2.3/2.4/2.6)
#      get_url: url={{ swift_download_url }} dest={{ swift_lib }}
#      when: "{{ hadoop_version }} == 2.3 or {{ hadoop_version }} == 2.4 or {{ hadoop_version }} == 2.6"
