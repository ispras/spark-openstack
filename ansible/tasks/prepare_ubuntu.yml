---

- name: update apt cache
  apt: update_cache=yes
  retries: 2
  tags:
    - install

- name: install packages
  package: name={{ item }} state=present
  with_items: "{{ ubuntu_14_04_packages }}"
  when: ansible_distribution == 'Ubuntu' and ansible_lsb.major_release|int <= 15 and not skip_packages|default(False)
  tags:
    - install

- name: install packages
  package: name={{ item }} state=present
  with_items: "{{ ubuntu_16_04_packages }}"
  when: ansible_distribution == 'Ubuntu' and ansible_lsb.major_release|int > 15 and not skip_packages|default(False)
  tags:
    - install


- name: disable net.ipv6.conf.all.disable_ipv6
  sysctl: name=net.ipv6.conf.all.disable_ipv6 value=1 state=present
  tags:
    - prepare

- name: disable net.ipv6.conf.lo.disable_ipv6
  sysctl: name=net.ipv6.conf.lo.disable_ipv6 value=1 state=present
  tags:
    - prepare

- name: increase hard file limits
  pam_limits: domain=* limit_type=hard limit_item=nofile value=1000000
  tags:
    - prepare

- name: increase soft file limits
  pam_limits: domain=* limit_type=soft limit_item=nofile value=1000000

- name: create hadoop group
  group: name=hadoop state=present
  tags:
    - prepare

- name: create hadoop user
  user: name={{ hadoop_user }} comment="Hadoop user" group=hadoop shell=/bin/bash
  tags:
    - prepare

- name: get Hadoop distro (except CDH4)
  get_url: url={{ hadoop_download_url }} dest=/usr/local/ checksum="md5:{{ hadoop_md5 }}"
  when: "'{{ inventory_hostname }}' == '{{ active_master_inventory_hostname }}' and {{ hadoop_version }} != 'cdh4'"
  tags:
    - install

- name: get Hadoop distro (CDH4)
  get_url: url={{ hadoop_download_url }} dest=/usr/local/
  when: "'{{ inventory_hostname }}' == '{{ active_master_inventory_hostname }}' and {{ hadoop_version }} == 'cdh4'"
  tags:
    - install


- name: distribute hadoop among slaves
  synchronize:
    src: "/usr/local/{{ hadoop_file }}.tar.gz"
    dest: "/usr/local/{{ hadoop_file }}.tar.gz"
    checksum: yes
  delegate_to: "{{ active_master_inventory_hostname }}"
  tags:
    - install

- name: unzip hadoop
  unarchive: copy=no src=/usr/local/{{ hadoop_file }}.tar.gz dest=/usr/local/ owner={{ hadoop_user }} group=hadoop
  tags:
    - install

- name: create hadoop symlink
  file: src=/usr/local/{{ hadoop_file }} dest=/usr/local/hadoop state=link
  tags:
    - install

- name: put needed swift library
  get_url: url={{ swift_download_url }} dest=/usr/local/{{ hadoop_file }}/share/hadoop/hdfs/lib/
  when: "{{ hadoop_version }} == 2.3 or {{ hadoop_version }} == 2.4 or {{ hadoop_version }} == 2.6 or {{ hadoop_version }} == 2.7"
  tags:
    - install

#- name: remove hadoop archive
#  file: path=/usr/local/{{ hadoop_file }}.tar.gz state=absent

- name: set user and priviliges on hadoop
  file: path=/usr/local/{{ hadoop_file }} owner={{ hadoop_user }} group=hadoop recurse=yes
  tags:
    - install

- name: get Spark distro
  get_url: url={{ spark_download_url }} dest=/opt/ checksum="md5:{{ spark_md5 }}"
  when: "'{{ inventory_hostname }}' == '{{ active_master_inventory_hostname }}'"
  tags:
    - install

#- name: put spark distro to master
#  copy: src={{ spark_arch }} dest=/opt/
#  when: "'{{ inventory_hostname }}' == '{{ active_master_inventory_hostname }}'"

- name: distribute spark distro among slaves
  synchronize:
    src: "/opt/{{ spark_file }}.tgz"
    dest: "/opt/{{ spark_file }}.tgz"
    checksum: yes
  delegate_to: "{{ active_master_inventory_hostname }}"
  tags:
    - install

- name: unzip spark
  unarchive: copy=no src=/opt/{{ spark_file }}.tgz dest=/opt
  tags:
    - install

#- name: remove spark archive
#  file: path=/opt/{{ spark_file }}.tgz state=absent

- name: create spark symlink
  file: src={{ spark_home }} dest=/opt/spark state=link
  tags:
    - install

- name: create spark symlink
  file: src={{ spark_home }} dest=/usr/local/spark state=link
  tags:
    - install

- name: create extra jars directory
  file: path={{ spark_extra_jars_dir }} owner={{ hadoop_user }} group=hadoop state=directory
  tags:
    - install

- name: copy extra jars
  copy: src={{item.path}} dest={{ spark_extra_jars_dir }}/{{item.name}} owner={{ hadoop_user }} group=hadoop mode=0644
  with_items: "{{extra_jars}}"
  tags:
    - install
